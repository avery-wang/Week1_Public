{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kNN-Problems.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3hHvV20eD58o"
      },
      "source": [
        "# Nearest Neighbors Problem Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z1h_AAj_D4kX",
        "colab": {}
      },
      "source": [
        "# -- imports --\n",
        "import numpy as np\n",
        "import pandas as po\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -- kNN --\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87tmgzNMb9tV",
        "colab_type": "text"
      },
      "source": [
        "## Problem 1\n",
        "\n",
        "Consider the following simple data-set:\n",
        "\n",
        "<img src=\"https://github.com/BeaverWorksMedlytics2020/Data_Public/raw/master/Images/Week1/knn_notebook_example_table.png\" alt=\"Example Table\" width=\"600\">\n",
        "\n",
        "Now consider the Sample:\n",
        "    $$X= 4, Y = 4, Z = 2$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gqjait37Qws0"
      },
      "source": [
        "Using kNN, what is the class for this sample for $k = 1$ and $k = 3?$ Use the Eucledian metric.\n",
        "\n",
        "$k = 1$: class 1\n",
        "$k = 3$: class 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MtE0uiKuTWsI"
      },
      "source": [
        "## Problem 2\n",
        "Earlier in the tutorial we were told that kNN depends on several factors, one of them being $k$. Consider the following datasets below, find the optimal value of $k$ that gives the highest accuracy. Visualize your data! Can you come up with some rule for getting a good idea of what $k$ is? \n",
        "\n",
        "HINT: look for a pattern/bound! Answer should be in terms of the size of the dataset $n$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aapncOgUo_5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sovle this problem for each of these datasets\n",
        "from sklearn.datasets import load_iris \n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.datasets import load_wine \n",
        "\n",
        "# Load those datasets into some easily accessible variables\n",
        "#The datasets are already normalized, so that saves us some steps!\n",
        "iris = load_iris()                    #iris dataset: size = 150\n",
        "breast_cancer = load_breast_cancer()  #diabetes dataset: size = 569\n",
        "wine = load_wine()                    #wine dataset: size 178\n",
        "\n",
        "# This function will perfom KNN classification for a specified k\n",
        "def split_train_test_dataset(dataset, k, test_size=0.2):\n",
        "    \"\"\"Loads and performs KNN classification on the provided dataset\"\"\"\n",
        "    # Grab and split the dataset\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        dataset.data, dataset.target, test_size=test_size, random_state=0)\n",
        "\n",
        "    # Build a KNN classifier, fit it and test its predictions\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    print(\"Validation Accuracy is {:5.1%}\".format(\n",
        "        accuracy_score(y_val, knn.predict(X_val))))\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQk-b90Kgz-S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "345e8539-97aa-41a9-8c22-b8d172c7b93e"
      },
      "source": [
        "data = [iris, breast_cancer, wine]\n",
        "\n",
        "for i in data:\n",
        "  for j in range(1, 20, 2):\n",
        "    split_train_test_dataset(i, j)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy is 100.0%\n",
            "Validation Accuracy is 96.7%\n",
            "Validation Accuracy is 96.7%\n",
            "Validation Accuracy is 100.0%\n",
            "Validation Accuracy is 100.0%\n",
            "Validation Accuracy is 100.0%\n",
            "Validation Accuracy is 100.0%\n",
            "Validation Accuracy is 100.0%\n",
            "Validation Accuracy is 100.0%\n",
            "Validation Accuracy is 100.0%\n",
            "Validation Accuracy is 91.2%\n",
            "Validation Accuracy is 91.2%\n",
            "Validation Accuracy is 93.9%\n",
            "Validation Accuracy is 94.7%\n",
            "Validation Accuracy is 96.5%\n",
            "Validation Accuracy is 96.5%\n",
            "Validation Accuracy is 96.5%\n",
            "Validation Accuracy is 96.5%\n",
            "Validation Accuracy is 96.5%\n",
            "Validation Accuracy is 96.5%\n",
            "Validation Accuracy is 77.8%\n",
            "Validation Accuracy is 77.8%\n",
            "Validation Accuracy is 80.6%\n",
            "Validation Accuracy is 77.8%\n",
            "Validation Accuracy is 75.0%\n",
            "Validation Accuracy is 72.2%\n",
            "Validation Accuracy is 75.0%\n",
            "Validation Accuracy is 72.2%\n",
            "Validation Accuracy is 77.8%\n",
            "Validation Accuracy is 77.8%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1_EbFlqzjAT",
        "colab_type": "text"
      },
      "source": [
        "Write a single mathematical expression describing the relationship you found between $n$ (the size of the dataset) and $k$ (the number of datapoints used to classify each validation datum).\n",
        "\n",
        "(YOUR ANSWER HERE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-vDZy0F3eyeH"
      },
      "source": [
        "## Problem 3\n",
        "Now, we will **be writing our k-NNA**. Recall that we said a kNN is comprised of a predictions and using those predictions to classify the data. Here we will try to mimic sklearn's kNN methods. We will be using the Pima diabetes dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YFfjG9G3lVO",
        "colab_type": "text"
      },
      "source": [
        "### Loading and splitting data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zbs8WICFgITd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "56c86791-6207-4e54-c8d4-ec2f3dd33bd3"
      },
      "source": [
        "# -- loading dataset -- #\n",
        "url = \"https://github.com/BeaverWorksMedlytics2020/Data_Public/raw/master/NotebookExampleData/Week1/diabetes.csv\"\n",
        "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
        "data = po.read_csv(url, names=names)\n",
        "\n",
        "# -- dropping NaN rows -- #\n",
        "invalid = ['plas', 'pres', 'skin', 'test', 'mass']\n",
        "\n",
        "for i in invalid:\n",
        "    data[i].replace(to_replace=0, value=np.nan, inplace=True)\n",
        "    \n",
        "data = data.dropna(axis=0).reset_index(drop=True)\n",
        "data"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>preg</th>\n",
              "      <th>plas</th>\n",
              "      <th>pres</th>\n",
              "      <th>skin</th>\n",
              "      <th>test</th>\n",
              "      <th>mass</th>\n",
              "      <th>pedi</th>\n",
              "      <th>age</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>89.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>168.0</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>78.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.248</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>197.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>543.0</td>\n",
              "      <td>30.5</td>\n",
              "      <td>0.158</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>189.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>846.0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.398</td>\n",
              "      <td>59</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>387</th>\n",
              "      <td>0</td>\n",
              "      <td>181.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>510.0</td>\n",
              "      <td>43.3</td>\n",
              "      <td>0.222</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>388</th>\n",
              "      <td>1</td>\n",
              "      <td>128.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>36.5</td>\n",
              "      <td>1.057</td>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>389</th>\n",
              "      <td>2</td>\n",
              "      <td>88.0</td>\n",
              "      <td>58.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>28.4</td>\n",
              "      <td>0.766</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>10</td>\n",
              "      <td>101.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>48.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>391</th>\n",
              "      <td>5</td>\n",
              "      <td>121.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>392 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     preg   plas  pres  skin   test  mass   pedi  age  class\n",
              "0       1   89.0  66.0  23.0   94.0  28.1  0.167   21      0\n",
              "1       0  137.0  40.0  35.0  168.0  43.1  2.288   33      1\n",
              "2       3   78.0  50.0  32.0   88.0  31.0  0.248   26      1\n",
              "3       2  197.0  70.0  45.0  543.0  30.5  0.158   53      1\n",
              "4       1  189.0  60.0  23.0  846.0  30.1  0.398   59      1\n",
              "..    ...    ...   ...   ...    ...   ...    ...  ...    ...\n",
              "387     0  181.0  88.0  44.0  510.0  43.3  0.222   26      1\n",
              "388     1  128.0  88.0  39.0  110.0  36.5  1.057   37      1\n",
              "389     2   88.0  58.0  26.0   16.0  28.4  0.766   22      0\n",
              "390    10  101.0  76.0  48.0  180.0  32.9  0.171   63      0\n",
              "391     5  121.0  72.0  23.0  112.0  26.2  0.245   30      0\n",
              "\n",
              "[392 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSUwHL6-4P2F",
        "colab_type": "text"
      },
      "source": [
        "Now, let's clearly define which columns will act as explanatory variables, and which column will be the target value, and split the dataset between your training data and testing data. Let's try an 80-20 split and use sklearn's [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) method (set random_state = 0 so we get the same output each time)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9MXZjxRcgy78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "56041670-1b84-4705-97a8-fd55a05a50a5"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# columns we will use to make predictions with (features!) feel free to play around with these\n",
        "X_cols = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age']\n",
        "# column that we want to predict\n",
        "y_col = 'class'\n",
        "\n",
        "\n",
        "# split X and y into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data[X_cols], data[y_col], test_size=0.2, random_state=0)\n",
        "\n",
        "# further split X and y of training into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n",
        "\n",
        "print('There are {} training samples with {} features and {} associated classification labels'.format(*X_train.shape, *y_train.shape))\n",
        "print('There are {} validation samples with {} features and {} associated classification labels'.format(*X_val.shape, *y_val.shape))\n",
        "print('There are {} test samples with {} features and {} associated classification labels'.format(*X_test.shape, *y_test.shape))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 250 training samples with 8 features and 250 associated classification labels\n",
            "There are 63 validation samples with 8 features and 63 associated classification labels\n",
            "There are 79 test samples with 8 features and 79 associated classification labels\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "De_EJnYKgz_6"
      },
      "source": [
        "### Normalizing Data\n",
        "\n",
        "Let's not forget to normalize the data! We'll use sklearn's StandardScaler normalization like we did before to normalize the training **and** validation/data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6PD6-ibriBJO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "84968582-b0e3-44bf-cfac-19f34d74cdfa"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "for i in list(X_train):\n",
        "    feature_data_train = X_train[i].values.reshape(-1, 1)\n",
        "    scaler.fit(feature_data_train)\n",
        "    X_train[i] = scaler.transform(feature_data_train)\n",
        "\n",
        "for j in list(X_test):\n",
        "    feature_data_test = X_test[j].values.reshape(-1, 1)\n",
        "    scaler.fit(feature_data_test)\n",
        "    X_test[j] = scaler.transform(feature_data_test)\n",
        "    \n",
        "for k in list(X_val):\n",
        "    feature_data_val = X_val[k].values.reshape(-1, 1)\n",
        "    scaler.fit(feature_data_val)\n",
        "    X_val[k] = scaler.transform(feature_data_val)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         preg      plas      pres  ...      mass      pedi       age\n",
            "173 -0.763913  0.494808 -2.166661  ... -0.657013  0.357848 -0.888644\n",
            "289 -0.763913 -1.193513 -0.269712  ...  0.659616 -0.379316 -0.705039\n",
            "115  1.130086  1.858451  1.109888  ...  0.408125  0.159717  1.773615\n",
            "335  0.498753 -0.024675  0.247638  ...  0.141841 -0.763924 -0.337831\n",
            "181  0.498753 -0.803900 -1.476861  ...  0.127047 -0.093774 -0.154227\n",
            "..        ...       ...       ...  ...       ...       ...       ...\n",
            "257  1.130086 -0.966239 -0.614612  ...  0.023492  0.602599  0.855595\n",
            "11   2.077085  0.040260 -0.097262  ... -0.301967 -0.950400  0.855595\n",
            "249 -0.763913  0.494808 -0.787061  ...  1.118217  0.014032 -0.980446\n",
            "101 -1.079579  0.527275 -0.528387  ...  1.399295 -0.291906 -0.705039\n",
            "248 -1.079579  0.364937 -0.269712  ...  1.354915 -0.484209 -0.705039\n",
            "\n",
            "[250 rows x 8 columns]\n",
            "         preg      plas      pres  ...      mass      pedi       age\n",
            "144 -0.371501  1.069242  0.053651  ... -0.694745 -0.511444 -0.118075\n",
            "280  1.274213  2.504587  1.515186  ...  0.294309 -0.248185  0.693046\n",
            "68  -0.371501 -0.294337 -1.261730  ... -0.010016 -0.569606 -0.827805\n",
            "372  0.451356  0.028616  1.222879  ...  0.994254 -0.774702  1.199997\n",
            "328 -0.097215 -0.473755  0.199805  ... -0.755610  0.691586 -0.320855\n",
            "..        ...       ...       ...  ...       ...       ...       ...\n",
            "100 -0.645787 -0.724940 -0.384809  ...  0.096498 -0.658379 -0.929195\n",
            "64  -0.371501  0.315685 -0.677116  ...  0.187795 -1.273669  0.084706\n",
            "55  -0.920072  1.643380  0.492112  ...  3.139741  0.780360 -0.523635\n",
            "260 -0.371501 -1.155544 -1.407884  ... -0.329556  1.420139 -0.929195\n",
            "214 -0.371501 -0.796708 -0.092502  ... -0.999070  0.174253 -0.929195\n",
            "\n",
            "[79 rows x 8 columns]\n",
            "         preg      plas      pres  ...      mass      pedi       age\n",
            "112  1.209666  0.235141  0.671314  ...  1.510127 -0.742346  2.632404\n",
            "42  -0.658200 -1.661758 -1.607084  ... -1.562683 -0.514171 -0.979388\n",
            "62   0.088946  1.319084 -0.467885  ...  0.116644 -0.425586  0.224543\n",
            "263  0.088946  1.108317 -0.040686  ... -0.228750 -0.661814 -0.076440\n",
            "206 -0.658200  1.379303 -0.183086  ...  1.057543  0.503221 -0.076440\n",
            "..        ...       ...       ...  ...       ...       ...       ...\n",
            "364  0.088946  0.957769 -0.467885  ... -0.276390 -0.589335 -0.678405\n",
            "270 -1.031774 -0.276721 -0.325485  ... -0.324031 -0.057821 -0.979388\n",
            "8   -0.658200 -0.336940 -0.040686  ...  0.128554  0.038817  0.525525\n",
            "217  0.462519  1.740617  0.528914  ...  0.414396 -0.672552  0.375034\n",
            "69   0.462519  0.837331 -0.610285  ... -0.085828 -0.745031 -0.828897\n",
            "\n",
            "[63 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hnv61aiiitxU"
      },
      "source": [
        "### Writing our kNN\n",
        "\n",
        "Now for the fun part! Fill in the 3 following methods, euclidean_dist(), predict(), and knn().\n",
        "\n",
        "The predict method that we'll make below needs to: \n",
        "1. Compute the euclidean distance between the “new” observation and all the data points in the training set. \n",
        "2. Assign the corresponding label to the observation\n",
        "3. Select the k nearest ones and perform a \"majority vote\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXkIw6zN3lVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Euclidean distance function from tutorial\n",
        "def euclidean_dist(datum1, datum2):\n",
        "    inner_val = 0.0\n",
        "    \n",
        "    for g in range(datum1.shape[0]):\n",
        "        inner_val += (datum1[g]- datum2[g]) ** 2\n",
        "    \n",
        "    distance = np.sqrt(inner_val)\n",
        "    return(distance)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FqJkm_ytjFgM",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "def predict(x_training, y_training, x_test_sample, k):\n",
        "    \n",
        "    # create list for distances and targets\n",
        "    distances = []\n",
        "    targets = []\n",
        "\n",
        "    # Needs work\n",
        "    for i in x_training:\n",
        "      distances.append(euclidean_dist(x_test_sample, i))\n",
        "    \n",
        "    for i in y_training:\n",
        "      targets.append(y_training)\n",
        "    \n",
        "    print(distances)\n",
        "    return 0\n",
        "    \n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BguZLcRa3lVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def knn(x_training, y_training, x_testing, k):\n",
        "    predictions = []\n",
        "    \n",
        "    for i in x_testing:\n",
        "      predictions.append(predict(x_training, y_training, i, k))\n",
        "    \n",
        "    return predictions"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4uhQZPIpjdo9"
      },
      "source": [
        "When done, test your code by running the methods here!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AHRJXVr7jcao",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "d7a73fa2-9217-47c0-8269-022cb2079e5b"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "predictions_slow = knn(X_train, y_train, X_val, k=5)\n",
        "\n",
        "print('Took {} seconds'.format(time.time() - start))\n",
        "print(\"Validation Accuracy is \", accuracy_score(y_val,predictions_slow)*100)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-c8ce05bea58f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpredictions_slow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Took {} seconds'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-213491e5e072>\u001b[0m in \u001b[0;36mknn\u001b[0;34m(x_training, y_training, x_testing, k)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_testing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m       \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-415f82db9baf>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(x_training, y_training, x_test_sample, k)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m       \u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meuclidean_dist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-16205fd1b90d>\u001b[0m in \u001b[0;36meuclidean_dist\u001b[0;34m(datum1, datum2)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0minner_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatum1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0minner_val\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdatum1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m \u001b[0mdatum2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a51RcbJ3lVq",
        "colab_type": "text"
      },
      "source": [
        "Check sklearn's predictions on validation data from the tutorial notebook and make sure they match yours. Sklearn is faster, but you should get the same answers."
      ]
    }
  ]
}